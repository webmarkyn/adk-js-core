/**
 * @license
 * Copyright 2025 Google LLC
 * SPDX-License-Identifier: Apache-2.0
 */
import { FunctionDeclaration } from '@google/genai';
import { LlmRequest } from '../models/llm_request.js';
import { ToolContext } from './tool_context.js';
/**
 * The parameters for `runAsync`.
 */
export interface RunAsyncToolRequest {
    args: Record<string, unknown>;
    toolContext: ToolContext;
}
/**
 * The parameters for `processLlmRequest`.
 */
export interface ToolProcessLlmRequest {
    toolContext: ToolContext;
    llmRequest: LlmRequest;
}
/**
 * Parameters for the BaseTool constructor.
 */
export interface BaseToolParams {
    name: string;
    description: string;
    isLongRunning?: boolean;
}
/**
 * The base class for all tools.
 */
export declare abstract class BaseTool {
    readonly name: string;
    readonly description: string;
    readonly isLongRunning: boolean;
    /**
     * Base constructor for a tool.
     *
     * @param params The parameters for `BaseTool`.
     */
    constructor(params: BaseToolParams);
    /**
     * Gets the OpenAPI specification of this tool in the form of a
     * FunctionDeclaration.
     *
     * NOTE
     * - Required if subclass uses the default implementation of
     *   `processLlmRequest` to add function declaration to LLM request.
     * - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for
     *   Gemini.
     *
     * @return The FunctionDeclaration of this tool, or undefined if it doesn't
     *     need to be added to LlmRequest.config.
     */
    _getDeclaration(): FunctionDeclaration | undefined;
    /**
     * Runs the tool with the given arguments and context.
     *
     * NOTE
     * - Required if this tool needs to run at the client side.
     * - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for
     *   Gemini.
     *
     * @param request The request to run the tool.
     * @return A promise that resolves to the tool response.
     */
    abstract runAsync(request: RunAsyncToolRequest): Promise<unknown>;
    /**
     * Processes the outgoing LLM request for this tool.
     *
     * Use cases:
     * - Most common use case is adding this tool to the LLM request.
     * - Some tools may just preprocess the LLM request before it's sent out.
     *
     * @param request The request to process the LLM request.
     */
    processLlmRequest({ toolContext, llmRequest }: ToolProcessLlmRequest): Promise<void>;
    /**
     * The Google API LLM variant to use.
     */
    get apiVariant(): import("../utils/variant_utils.js").GoogleLLMVariant;
}

/**
  * @license
  * Copyright 2025 Google LLC
  * SPDX-License-Identifier: Apache-2.0
  */

var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
var base_llm_exports = {};
__export(base_llm_exports, {
  BaseLlm: () => BaseLlm,
  isBaseLlm: () => isBaseLlm
});
module.exports = __toCommonJS(base_llm_exports);
var import_client_labels = require("../utils/client_labels.js");
/**
 * @license
 * Copyright 2025 Google LLC
 * SPDX-License-Identifier: Apache-2.0
 */
var _a;
const BASE_MODEL_SYMBOL = Symbol.for("google.adk.baseModel");
function isBaseLlm(obj) {
  return typeof obj === "object" && obj !== null && BASE_MODEL_SYMBOL in obj && obj[BASE_MODEL_SYMBOL] === true;
}
_a = BASE_MODEL_SYMBOL;
class BaseLlm {
  /**
   * Creates an instance of BaseLLM.
   * @param params The parameters for creating a BaseLlm instance.
   * @param params.model The name of the LLM, e.g. gemini-1.5-flash or
   *     gemini-1.5-flash-001.
   */
  constructor({ model }) {
    /**
     * A unique symbol to identify BaseLlm classes.
     */
    this[_a] = true;
    this.model = model;
  }
  get trackingHeaders() {
    const labels = (0, import_client_labels.getClientLabels)();
    const headerValue = labels.join(" ");
    return {
      "x-goog-api-client": headerValue,
      "user-agent": headerValue
    };
  }
  /**
   * Appends a user content, so that model can continue to output.
   *
   * @param llmRequest LlmRequest, the request to send to the LLM.
   */
  maybeAppendUserContent(llmRequest) {
    var _a2;
    if (llmRequest.contents.length === 0) {
      llmRequest.contents.push({
        role: "user",
        parts: [
          { text: "Handle the requests as specified in the System Instruction." }
        ]
      });
    }
    if (((_a2 = llmRequest.contents[llmRequest.contents.length - 1]) == null ? void 0 : _a2.role) !== "user") {
      llmRequest.contents.push({
        role: "user",
        parts: [{
          text: "Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."
        }]
      });
    }
  }
}
/**
 * List of supported models in regex for LlmRegistry.
 */
BaseLlm.supportedModels = [];
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  BaseLlm,
  isBaseLlm
});

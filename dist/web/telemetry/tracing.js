var __getOwnPropSymbols = Object.getOwnPropertySymbols;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __propIsEnum = Object.prototype.propertyIsEnumerable;
var __objRest = (source, exclude) => {
  var target = {};
  for (var prop in source)
    if (__hasOwnProp.call(source, prop) && exclude.indexOf(prop) < 0)
      target[prop] = source[prop];
  if (source != null && __getOwnPropSymbols)
    for (var prop of __getOwnPropSymbols(source)) {
      if (exclude.indexOf(prop) < 0 && __propIsEnum.call(source, prop))
        target[prop] = source[prop];
    }
  return target;
};
/**
 * @license
 * Copyright 2025 Google LLC
 * SPDX-License-Identifier: Apache-2.0
 */
import { trace, context } from "@opentelemetry/api";
import { version } from "../version.js";
const GEN_AI_AGENT_DESCRIPTION = "gen_ai.agent.description";
const GEN_AI_AGENT_NAME = "gen_ai.agent.name";
const GEN_AI_CONVERSATION_ID = "gen_ai.conversation.id";
const GEN_AI_OPERATION_NAME = "gen_ai.operation.name";
const GEN_AI_TOOL_CALL_ID = "gen_ai.tool.call.id";
const GEN_AI_TOOL_DESCRIPTION = "gen_ai.tool.description";
const GEN_AI_TOOL_NAME = "gen_ai.tool.name";
const GEN_AI_TOOL_TYPE = "gen_ai.tool.type";
const tracer = trace.getTracer(
  "gcp.vertex.agent",
  version
);
function safeJsonSerialize(obj) {
  try {
    return JSON.stringify(obj);
  } catch (error) {
    return "<not serializable>";
  }
}
function traceAgentInvocation({
  agent,
  invocationContext
}) {
  const span = trace.getActiveSpan();
  if (!span) return;
  span.setAttributes({
    [GEN_AI_OPERATION_NAME]: "invoke_agent",
    // Conditionally Required
    [GEN_AI_AGENT_DESCRIPTION]: agent.description,
    [GEN_AI_AGENT_NAME]: agent.name,
    [GEN_AI_CONVERSATION_ID]: invocationContext.session.id
  });
}
function traceToolCall({
  tool,
  args,
  functionResponseEvent
}) {
  var _a, _b;
  const span = trace.getActiveSpan();
  if (!span) return;
  span.setAttributes({
    [GEN_AI_OPERATION_NAME]: "execute_tool",
    [GEN_AI_TOOL_DESCRIPTION]: tool.description || "",
    [GEN_AI_TOOL_NAME]: tool.name,
    // e.g. FunctionTool
    [GEN_AI_TOOL_TYPE]: tool.constructor.name,
    // Setting empty llm request and response (as UI expect these) while not
    // applicable for tool_response.
    "gcp.vertex.agent.llm_request": "{}",
    "gcp.vertex.agent.llm_response": "{}",
    "gcp.vertex.agent.tool_call_args": shouldAddRequestResponseToSpans() ? safeJsonSerialize(args) : "{}"
  });
  let toolCallId = "<not specified>";
  let toolResponse = "<not specified>";
  if ((_a = functionResponseEvent.content) == null ? void 0 : _a.parts) {
    const responseParts = functionResponseEvent.content.parts;
    const functionResponse = (_b = responseParts[0]) == null ? void 0 : _b.functionResponse;
    if (functionResponse == null ? void 0 : functionResponse.id) {
      toolCallId = functionResponse.id;
    }
    if (functionResponse == null ? void 0 : functionResponse.response) {
      toolResponse = functionResponse.response;
    }
  }
  if (typeof toolResponse !== "object" || toolResponse === null) {
    toolResponse = { result: toolResponse };
  }
  span.setAttributes({
    [GEN_AI_TOOL_CALL_ID]: toolCallId,
    "gcp.vertex.agent.event_id": functionResponseEvent.id,
    "gcp.vertex.agent.tool_response": shouldAddRequestResponseToSpans() ? safeJsonSerialize(toolResponse) : "{}"
  });
}
function traceMergedToolCalls({
  responseEventId,
  functionResponseEvent
}) {
  const span = trace.getActiveSpan();
  if (!span) return;
  span.setAttributes({
    [GEN_AI_OPERATION_NAME]: "execute_tool",
    [GEN_AI_TOOL_NAME]: "(merged tools)",
    [GEN_AI_TOOL_DESCRIPTION]: "(merged tools)",
    [GEN_AI_TOOL_CALL_ID]: responseEventId,
    "gcp.vertex.agent.tool_call_args": "N/A",
    "gcp.vertex.agent.event_id": responseEventId,
    // Setting empty llm request and response (as UI expect these) while not
    // applicable for tool_response.
    "gcp.vertex.agent.llm_request": "{}",
    "gcp.vertex.agent.llm_response": "{}"
  });
  span.setAttribute("gcp.vertex.agent.tool_response", shouldAddRequestResponseToSpans() ? safeJsonSerialize(functionResponseEvent) : "{}");
}
function traceCallLlm({
  invocationContext,
  eventId,
  llmRequest,
  llmResponse
}) {
  var _a, _b, _c;
  const span = trace.getActiveSpan();
  if (!span) return;
  span.setAttributes({
    "gen_ai.system": "gcp.vertex.agent",
    "gen_ai.request.model": llmRequest.model,
    "gcp.vertex.agent.invocation_id": invocationContext.invocationId,
    "gcp.vertex.agent.session_id": invocationContext.session.id,
    "gcp.vertex.agent.event_id": eventId,
    // Consider removing once GenAI SDK provides a way to record this info.
    "gcp.vertex.agent.llm_request": shouldAddRequestResponseToSpans() ? safeJsonSerialize(buildLlmRequestForTrace(llmRequest)) : "{}"
  });
  if ((_a = llmRequest.config) == null ? void 0 : _a.topP) {
    span.setAttribute("gen_ai.request.top_p", llmRequest.config.topP);
  }
  if (((_b = llmRequest.config) == null ? void 0 : _b.maxOutputTokens) !== void 0) {
    span.setAttribute("gen_ai.request.max_tokens", llmRequest.config.maxOutputTokens);
  }
  span.setAttribute("gcp.vertex.agent.llm_response", shouldAddRequestResponseToSpans() ? safeJsonSerialize(llmResponse) : "{}");
  if (llmResponse.usageMetadata) {
    span.setAttribute("gen_ai.usage.input_tokens", llmResponse.usageMetadata.promptTokenCount || 0);
  }
  if ((_c = llmResponse.usageMetadata) == null ? void 0 : _c.candidatesTokenCount) {
    span.setAttribute("gen_ai.usage.output_tokens", llmResponse.usageMetadata.candidatesTokenCount);
  }
  if (llmResponse.finishReason) {
    const finishReasonValue = typeof llmResponse.finishReason === "string" ? llmResponse.finishReason.toLowerCase() : String(llmResponse.finishReason).toLowerCase();
    span.setAttribute("gen_ai.response.finish_reasons", [finishReasonValue]);
  }
}
function traceSendData({
  invocationContext,
  eventId,
  data
}) {
  const span = trace.getActiveSpan();
  if (!span) return;
  span.setAttributes({
    "gcp.vertex.agent.invocation_id": invocationContext.invocationId,
    "gcp.vertex.agent.event_id": eventId
  });
  span.setAttribute("gcp.vertex.agent.data", shouldAddRequestResponseToSpans() ? safeJsonSerialize(data) : "{}");
}
function buildLlmRequestForTrace(llmRequest) {
  const result = {
    model: llmRequest.model,
    contents: []
  };
  if (llmRequest.config) {
    const _a = llmRequest.config, { responseSchema } = _a, cleanConfig = __objRest(_a, ["responseSchema"]);
    result.config = cleanConfig;
  }
  result.contents = llmRequest.contents.map((content) => {
    var _a2;
    return {
      role: content.role,
      parts: ((_a2 = content.parts) == null ? void 0 : _a2.filter((part) => !part.inlineData)) || []
    };
  });
  return result;
}
function bindAsyncGenerator(ctx, generator) {
  return {
    // Bind the next() method to execute within the provided context
    next: context.bind(ctx, generator.next.bind(generator)),
    // Bind the return() method to execute within the provided context
    return: context.bind(ctx, generator.return.bind(generator)),
    // Bind the throw() method to execute within the provided context
    throw: context.bind(ctx, generator.throw.bind(generator)),
    // Ensure the async iterator symbol also returns a context-bound generator
    [Symbol.asyncIterator]() {
      return bindAsyncGenerator(ctx, generator[Symbol.asyncIterator]());
    }
  };
}
function shouldAddRequestResponseToSpans() {
  const envValue = process.env.ADK_CAPTURE_MESSAGE_CONTENT_IN_SPANS || "true";
  return envValue === "true" || envValue === "1";
}
export {
  bindAsyncGenerator,
  traceAgentInvocation,
  traceCallLlm,
  traceMergedToolCalls,
  traceSendData,
  traceToolCall,
  tracer
};
